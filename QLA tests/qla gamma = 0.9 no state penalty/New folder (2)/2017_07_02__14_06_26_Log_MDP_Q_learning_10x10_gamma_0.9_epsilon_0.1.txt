Logfile for mdp Q_learning_10x10_gamma_0.9_epsilon_0.1
| +2.824 || +0.985 || +1.853 || +1.351 || +4.304 || +3.874 || +0.798 || +2.542 || +0.886 || +1.668 |
| +1.094 || +4.304 || +2.059 || +1.853 || +1.351 || +1.216 || +1.094 || +1.216 || +4.783 || +0.985 |
| +1.501 || +4.783 || +4.304 || +5.904 || +6.560 || +7.289 || +8.099 || +5.904 || +6.560 || +1.216 |
| +2.059 || +4.304 || +5.904 || +6.560 || +5.904 || +6.560 || +8.999 || +6.560 || +5.904 || +1.501 |
| +1.853 || +1.668 || +1.853 || +2.542 || +5.314 || -0.001 || +9.999 || +5.904 || +5.314 || +1.094 |
| +1.501 || +1.501 || +4.783 || +2.824 || +8.999 || +9.999 || +8.999 || +5.314 || +4.783 || +1.216 |
| +1.150 || +4.783 || +5.314 || +4.783 || +8.099 || +8.999 || +8.099 || +7.289 || +2.824 || +3.138 |
| +1.668 || +3.486 || +3.874 || +6.560 || +7.289 || +6.560 || +4.783 || +5.314 || +3.138 || +2.287 |
| +3.486 || +3.138 || +4.304 || +5.904 || +6.560 || +7.289 || +4.304 || +4.783 || +0.798 || +0.798 |
| +3.138 || +4.304 || +3.874 || +5.314 || +5.904 || +2.824 || +3.874 || +1.216 || +1.094 || +0.148 |

Policy p(S) = 
|   DOWN ||   DOWN ||   DOWN ||   DOWN ||   LEFT ||  RIGHT ||   DOWN ||   DOWN ||     UP ||   LEFT |
|  RIGHT ||   DOWN ||   DOWN ||   DOWN ||     UP ||  RIGHT ||     UP ||  RIGHT ||   DOWN ||   DOWN |
|     UP ||  RIGHT ||  RIGHT ||   DOWN ||   DOWN ||  RIGHT ||   DOWN ||   DOWN ||   LEFT ||   DOWN |
|  RIGHT ||     UP ||     UP ||  RIGHT ||  RIGHT ||     UP ||   DOWN ||   LEFT ||  RIGHT ||   LEFT |
|     UP ||   DOWN ||   DOWN ||   DOWN ||     UP ||  RIGHT ||   LEFT ||     UP ||   LEFT ||   DOWN |
|   LEFT ||   DOWN ||   DOWN ||   LEFT ||  RIGHT ||     UP ||     UP ||   LEFT ||   LEFT ||   DOWN |
|   DOWN ||  RIGHT ||  RIGHT ||   DOWN ||  RIGHT ||     UP ||   LEFT ||   LEFT ||   LEFT ||   LEFT |
|   DOWN ||  RIGHT ||  RIGHT ||  RIGHT ||     UP ||   DOWN ||     UP ||     UP ||   LEFT ||   LEFT |
|  RIGHT ||     UP ||     UP ||  RIGHT ||     UP ||     UP ||     UP ||     UP ||  RIGHT ||   LEFT |
|     UP ||  RIGHT ||  RIGHT ||     UP ||     UP ||     UP ||   LEFT ||   DOWN ||   LEFT ||  RIGHT |

Minimum length of path to goal: 10
Maximum total reward of path: 10.0
100 simulated runs of probabilistic agent results in: 
 Average pathlength: 15.35 
 Average reward: 10.0
