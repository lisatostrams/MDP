Logfile for mdp Value_Iteration_4x3_gamma_0.1
V(S) = 
| +0.849 || +0.908 || +0.958 || +0.000 |
| +0.788 || +0.000 || +0.700 || +0.000 |
| +0.688 || +0.622 || +0.622 || +0.401 |

Policy p(S) = 
|  RIGHT ||  RIGHT ||  RIGHT ||       |
|     UP ||       ||     UP ||       |
|     UP ||   LEFT ||     UP ||   LEFT |

Minimum length of path to goal: 5
Max total reward of path: 0.84
100 simulated runs of probabilistic agent results in: 
 Average pathlength: 6.83 
 Average reward: 0.7667999999999999
