Logfile for mdp Q_learning_10x10_gamma_1.0_epsilon_0.1
| +8.475 || +8.475 || +9.115 || +9.235 || +9.355 || +9.395 || +9.435 || -0.001 || +9.995 || -0.005 |
| +8.675 || +8.555 || +9.235 || +9.155 || +9.275 || +9.355 || +9.475 || -0.003 || +9.955 || +9.995 |
| +9.115 || +9.395 || +9.275 || +9.275 || +9.435 || +9.475 || +9.515 || -0.004 || +9.915 || +9.955 |
| +8.995 || +9.035 || +9.315 || -0.002 || +9.475 || +9.555 || +9.635 || -0.004 || +9.875 || +9.915 |
| +8.515 || +9.235 || +9.075 || -0.000 || +9.515 || +9.635 || +9.555 || -0.005 || +9.835 || +9.715 |
| +8.755 || +9.115 || +9.075 || -0.001 || +9.555 || +9.675 || +9.715 || +9.755 || +9.795 || +9.715 |
| +8.715 || +9.235 || +8.995 || -0.000 || -0.001 || -0.001 || -0.002 || -0.000 || -0.004 || -0.004 |
| +8.675 || +8.675 || +9.235 || -0.000 || -1.086 || -1.122 || -1.082 || -1.082 || -1.084 || -1.044 |
| +9.035 || +9.155 || +8.795 || +8.595 || +8.595 || +8.755 || -1.121 || -1.124 || -1.084 || -1.084 |
| +8.155 || +8.875 || +8.915 || +8.275 || +8.595 || -1.048 || -1.088 || -1.084 || -1.084 || -1.084 |

Policy p(S) = 
|   DOWN ||   LEFT ||  RIGHT ||  RIGHT ||  RIGHT ||  RIGHT ||   DOWN ||  RIGHT ||  RIGHT ||   LEFT |
|   DOWN ||   LEFT ||   DOWN ||   DOWN ||  RIGHT ||   DOWN ||   DOWN ||   LEFT ||  RIGHT ||     UP |
|   DOWN ||  RIGHT ||  RIGHT ||  RIGHT ||   DOWN ||  RIGHT ||   DOWN ||  RIGHT ||  RIGHT ||     UP |
|     UP ||  RIGHT ||     UP ||   DOWN ||   DOWN ||   DOWN ||   DOWN ||   LEFT ||     UP ||     UP |
|     UP ||     UP ||     UP ||   DOWN ||   DOWN ||  RIGHT ||   DOWN ||  RIGHT ||     UP ||     UP |
|     UP ||  RIGHT ||     UP ||   DOWN ||  RIGHT ||  RIGHT ||  RIGHT ||  RIGHT ||     UP ||     UP |
|   DOWN ||     UP ||     UP ||     UP ||  RIGHT ||   DOWN ||   DOWN ||   DOWN ||     UP ||     UP |
|   DOWN ||  RIGHT ||   LEFT ||     UP ||   LEFT ||  RIGHT ||  RIGHT ||   LEFT ||     UP ||   DOWN |
|  RIGHT ||     UP ||   LEFT ||   LEFT ||   LEFT ||   LEFT ||     UP ||  RIGHT ||  RIGHT ||   DOWN |
|  RIGHT ||     UP ||     UP ||     UP ||   LEFT ||   LEFT ||   LEFT ||  RIGHT ||  RIGHT ||  RIGHT |

Minimum length of path to goal: 100
Maximum total reward of path: -4.000000000000003
100 simulated runs of probabilistic agent results in: 
 Average pathlength: 41.3 
 Average reward: 8.387999999999998
