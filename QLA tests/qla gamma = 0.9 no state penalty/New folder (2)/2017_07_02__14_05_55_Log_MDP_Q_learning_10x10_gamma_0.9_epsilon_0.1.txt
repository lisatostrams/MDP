Logfile for mdp Q_learning_10x10_gamma_0.9_epsilon_0.1
| +1.215 || +1.667 || +1.852 || +2.541 || +2.823 || +4.782 || +5.313 || +4.782 || +1.501 || +1.350 |
| +1.350 || +1.501 || +1.667 || +1.852 || +2.058 || +3.486 || +4.782 || +1.501 || +1.215 || +1.350 |
| +1.501 || +3.873 || +2.287 || +3.137 || +5.313 || +7.288 || +4.303 || +1.667 || +2.823 || +1.501 |
| +1.501 || +1.501 || +3.137 || +5.313 || +5.903 || +9.997 || +7.288 || +2.823 || +3.137 || +1.215 |
| +5.313 || +2.541 || +8.098 || +5.903 || +9.997 || -0.003 || +6.559 || +4.782 || +2.823 || +0.984 |
| +1.350 || +2.823 || +3.137 || +6.559 || +7.288 || +9.997 || +7.288 || +5.313 || +5.903 || +1.350 |
| +4.303 || +4.782 || +5.313 || +5.903 || +6.559 || +8.997 || +6.559 || +4.782 || +6.559 || +2.541 |
| +3.873 || +3.486 || +3.873 || +6.559 || +7.288 || +8.098 || +5.903 || +4.303 || +1.094 || +0.797 |
| +2.823 || +3.137 || +4.303 || +5.903 || +5.313 || +3.873 || +4.303 || +3.873 || +1.501 || +1.094 |
| +1.446 || +3.486 || +4.782 || +2.823 || +3.873 || +1.852 || +2.541 || +4.303 || +1.094 || +0.984 |

Policy p(S) = 
|   DOWN ||  RIGHT ||  RIGHT ||  RIGHT ||   DOWN ||   DOWN ||   DOWN ||   LEFT ||   LEFT ||   LEFT |
|  RIGHT ||  RIGHT ||  RIGHT ||     UP ||   DOWN ||   DOWN ||   DOWN ||   LEFT ||     UP ||   LEFT |
|  RIGHT ||  RIGHT ||   DOWN ||   DOWN ||  RIGHT ||   DOWN ||   LEFT ||     UP ||     UP ||   DOWN |
|   LEFT ||     UP ||  RIGHT ||  RIGHT ||   DOWN ||   DOWN ||   DOWN ||   LEFT ||     UP ||   LEFT |
|  RIGHT ||  RIGHT ||     UP ||  RIGHT ||  RIGHT ||   LEFT ||   DOWN ||   LEFT ||     UP ||   DOWN |
|     UP ||  RIGHT ||     UP ||     UP ||   DOWN ||     UP ||   LEFT ||   LEFT ||   LEFT ||   DOWN |
|   DOWN ||  RIGHT ||  RIGHT ||  RIGHT ||     UP ||     UP ||     UP ||   DOWN ||   LEFT ||   DOWN |
|  RIGHT ||  RIGHT ||   LEFT ||     UP ||     UP ||     UP ||     UP ||   LEFT ||   LEFT ||   DOWN |
|  RIGHT ||     UP ||     UP ||  RIGHT ||  RIGHT ||     UP ||     UP ||     UP ||   LEFT ||   DOWN |
|   LEFT ||  RIGHT ||  RIGHT ||     UP ||     UP ||     UP ||  RIGHT ||     UP ||   LEFT ||   LEFT |

Minimum length of path to goal: 100
Maximum total reward of path: 0.0
100 simulated runs of probabilistic agent results in: 
 Average pathlength: 36.59 
 Average reward: 10.0
