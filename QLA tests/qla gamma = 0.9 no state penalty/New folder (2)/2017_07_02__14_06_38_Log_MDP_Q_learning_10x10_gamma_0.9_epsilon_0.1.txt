Logfile for mdp Q_learning_10x10_gamma_0.9_epsilon_0.1
| +1.215 || +0.886 || +2.287 || +1.350 || +1.500 || +3.137 || +1.852 || +2.287 || +0.424 || +0.000 |
| +1.215 || +0.984 || +2.541 || +4.303 || +3.872 || +2.823 || +3.137 || +2.287 || +1.350 || +0.000 |
| +4.303 || +1.094 || +5.312 || +3.137 || +5.312 || +8.996 || +6.558 || +1.350 || +3.485 || +0.886 |
| +3.872 || +2.823 || +3.872 || +3.485 || +8.996 || +9.995 || +8.996 || +1.852 || +2.541 || +2.823 |
| +2.287 || +1.667 || +3.485 || +4.781 || +5.312 || -0.005 || +8.096 || +2.541 || +2.287 || +2.541 |
| +1.667 || +5.312 || +4.781 || +6.558 || +4.781 || +9.995 || +5.902 || +5.312 || +1.350 || +1.215 |
| +0.984 || +4.781 || +6.558 || +3.872 || +8.096 || +8.996 || +5.312 || +1.350 || +1.500 || +3.872 |
| +4.781 || +4.303 || +3.872 || +5.312 || +7.287 || +4.303 || +1.350 || +2.287 || +1.350 || +1.215 |
| +3.485 || +4.781 || +4.303 || +4.781 || +4.303 || +4.781 || +1.215 || +2.541 || +1.852 || +2.541 |
| +3.137 || +3.485 || +3.872 || +5.312 || +4.781 || +1.094 || +1.350 || +0.984 || +0.984 || +2.287 |

Policy p(S) = 
|     UP ||  RIGHT ||   DOWN ||   LEFT ||  RIGHT ||   DOWN ||   DOWN ||   LEFT ||     UP ||   DOWN |
|  RIGHT ||  RIGHT ||   DOWN ||   DOWN ||   DOWN ||   DOWN ||   LEFT ||   LEFT ||   LEFT ||   LEFT |
|  RIGHT ||   LEFT ||  RIGHT ||  RIGHT ||   DOWN ||   LEFT ||     UP ||   DOWN ||   DOWN ||   DOWN |
|     UP ||   DOWN ||     UP ||   DOWN ||   DOWN ||   DOWN ||   LEFT ||   DOWN ||   LEFT ||   DOWN |
|  RIGHT ||   DOWN ||     UP ||  RIGHT ||   LEFT ||     UP ||     UP ||     UP ||     UP ||     UP |
|     UP ||  RIGHT ||   LEFT ||   DOWN ||     UP ||     UP ||     UP ||   LEFT ||     UP ||   DOWN |
|     UP ||     UP ||  RIGHT ||  RIGHT ||  RIGHT ||     UP ||   LEFT ||   DOWN ||  RIGHT ||   LEFT |
|  RIGHT ||  RIGHT ||     UP ||     UP ||     UP ||   LEFT ||     UP ||   DOWN ||   DOWN ||     UP |
|  RIGHT ||     UP ||  RIGHT ||   LEFT ||     UP ||   LEFT ||   LEFT ||     UP ||   LEFT ||   DOWN |
|  RIGHT ||  RIGHT ||     UP ||  RIGHT ||     UP ||     UP ||   DOWN ||   DOWN ||   LEFT ||   DOWN |

Minimum length of path to goal: 100
Maximum total reward of path: 0.0
100 simulated runs of probabilistic agent results in: 
 Average pathlength: 27.79 
 Average reward: 9.7
