Logfile for mdp Q_learning_10x10_gamma_0.9_epsilon_0.1
| -0.001 || +2.059 || +1.853 || +3.874 || +2.059 || +3.874 || +8.100 || +9.000 || +10.000 || -0.000 |
| +2.059 || +1.853 || +3.138 || +4.305 || +4.783 || +4.305 || +5.905 || +8.100 || +9.000 || +10.000 |
| +1.216 || +2.059 || +1.501 || +3.874 || +4.305 || +5.905 || +6.561 || +7.290 || +8.100 || +9.000 |
| +1.094 || +1.501 || +2.542 || +1.853 || +3.487 || +5.314 || +5.314 || +4.783 || +7.290 || +6.561 |
| +1.094 || +2.059 || +2.288 || +3.138 || +3.487 || +3.874 || +3.487 || +3.874 || +5.314 || +7.290 |
| +0.718 || +1.216 || +1.094 || +1.216 || +3.138 || +3.487 || +3.138 || +5.314 || +5.905 || +5.314 |
| +0.798 || +1.351 || +2.288 || +3.138 || +2.288 || +3.874 || +3.487 || +4.783 || +5.314 || +5.905 |
| +0.886 || +1.501 || +2.542 || +2.288 || +2.059 || +2.824 || +2.059 || +2.824 || +3.138 || +2.542 |
| +1.216 || +1.094 || +0.798 || +2.059 || +1.501 || +2.059 || +1.501 || +1.501 || +2.824 || +0.203 |
| +0.438 || +1.853 || +2.059 || +1.853 || +1.216 || +1.853 || +2.059 || +1.216 || +3.138 || +1.501 |

Policy p(S) = 
|  RIGHT ||   DOWN ||   DOWN ||   LEFT ||   DOWN ||   LEFT ||   DOWN ||  RIGHT ||  RIGHT ||     UP |
|  RIGHT ||  RIGHT ||   DOWN ||  RIGHT ||   DOWN ||   DOWN ||  RIGHT ||  RIGHT ||     UP ||     UP |
|   DOWN ||     UP ||   DOWN ||     UP ||  RIGHT ||  RIGHT ||     UP ||     UP ||  RIGHT ||     UP |
|   DOWN ||  RIGHT ||  RIGHT ||  RIGHT ||  RIGHT ||     UP ||     UP ||   LEFT ||  RIGHT ||     UP |
|   LEFT ||     UP ||  RIGHT ||  RIGHT ||     UP ||     UP ||  RIGHT ||     UP ||     UP ||     UP |
|  RIGHT ||   DOWN ||     UP ||     UP ||     UP ||     UP ||     UP ||  RIGHT ||     UP ||     UP |
|     UP ||   DOWN ||  RIGHT ||  RIGHT ||     UP ||     UP ||     UP ||     UP ||  RIGHT ||     UP |
|     UP ||  RIGHT ||  RIGHT ||  RIGHT ||  RIGHT ||     UP ||   LEFT ||     UP ||  RIGHT ||  RIGHT |
|  RIGHT ||  RIGHT ||     UP ||  RIGHT ||     UP ||     UP ||     UP ||   DOWN ||   DOWN ||   DOWN |
|  RIGHT ||  RIGHT ||  RIGHT ||     UP ||     UP ||  RIGHT ||     UP ||     UP ||     UP ||   LEFT |

Minimum length of path to goal: 18
Maximum total reward of path: 10.0
100 simulated runs of probabilistic agent results in: 
 Average pathlength: 23.34 
 Average reward: 10.0
