Logfile for mdp Q_learning_10x10_gamma_0.9_epsilon_0.1
| +0.250 || +1.351 || +2.287 || +2.541 || +6.560 || +2.541 || +2.824 || +4.782 || +1.853 || +1.667 |
| +2.541 || +2.287 || +2.824 || +4.304 || +5.904 || +3.486 || +3.138 || +3.486 || +3.873 || +1.853 |
| +1.094 || +5.904 || +2.824 || +5.904 || +3.486 || +8.998 || +2.824 || +3.138 || +3.486 || +3.873 |
| +1.216 || +1.501 || +7.289 || +8.098 || +4.782 || +5.313 || +3.138 || +2.824 || +2.541 || +1.094 |
| +1.351 || +7.289 || +6.560 || +4.782 || +9.998 || -0.002 || +9.998 || +3.138 || +2.287 || +1.351 |
| +4.782 || +4.304 || +2.541 || +4.304 || +3.873 || +9.998 || +8.998 || +8.098 || +3.873 || +2.824 |
| +1.667 || +4.782 || +5.313 || +3.873 || +4.304 || +8.998 || +2.824 || +3.138 || +2.287 || +2.541 |
| +1.667 || +1.853 || +3.138 || +4.304 || +3.873 || +3.486 || +2.541 || +5.313 || +3.138 || +1.216 |
| +1.501 || +1.667 || +4.304 || +5.904 || +4.304 || +3.873 || +2.824 || +2.541 || +1.501 || +1.667 |
| +6.413 || +4.304 || +2.059 || +5.313 || +2.059 || +5.313 || +3.138 || +1.501 || +4.782 || +1.094 |

Policy p(S) = 
|  RIGHT ||   DOWN ||  RIGHT ||   DOWN ||   DOWN ||   DOWN ||  RIGHT ||  RIGHT ||   LEFT ||   LEFT |
|  RIGHT ||   DOWN ||     UP ||   DOWN ||   DOWN ||   DOWN ||   DOWN ||   DOWN ||     UP ||   DOWN |
|   DOWN ||  RIGHT ||   DOWN ||   DOWN ||   DOWN ||   DOWN ||     UP ||   LEFT ||   DOWN ||     UP |
|   DOWN ||     UP ||   DOWN ||   DOWN ||   DOWN ||   DOWN ||   DOWN ||   DOWN ||   LEFT ||   DOWN |
|   LEFT ||  RIGHT ||   LEFT ||  RIGHT ||  RIGHT ||   LEFT ||   LEFT ||   LEFT ||     UP ||   DOWN |
|   DOWN ||     UP ||  RIGHT ||  RIGHT ||   DOWN ||   LEFT ||   LEFT ||     UP ||   LEFT ||   LEFT |
|   DOWN ||  RIGHT ||  RIGHT ||     UP ||  RIGHT ||     UP ||  RIGHT ||     UP ||   LEFT ||     UP |
|  RIGHT ||  RIGHT ||  RIGHT ||     UP ||   DOWN ||     UP ||     UP ||   LEFT ||   LEFT ||     UP |
|     UP ||     UP ||     UP ||     UP ||   LEFT ||     UP ||     UP ||     UP ||   LEFT ||   DOWN |
|  RIGHT ||  RIGHT ||  RIGHT ||  RIGHT ||     UP ||     UP ||     UP ||   LEFT ||   LEFT ||   DOWN |

Minimum length of path to goal: 100
Maximum total reward of path: 0.0
100 simulated runs of probabilistic agent results in: 
 Average pathlength: 40.47 
 Average reward: 9.6
